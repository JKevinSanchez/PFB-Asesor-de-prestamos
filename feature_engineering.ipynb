{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d16fbe7e-63a0-4f67-8d0b-d1bc543c3cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "f = \"accepted_2007_to_2018Q4.csv\"\n",
    "\n",
    "def limpieza_data():\n",
    "    num_lines = sum(1 for i in open(f))\n",
    "\n",
    "    size = 2_200_000\n",
    "    ids = random.sample(range(1, num_lines), size)\n",
    "\n",
    "    column_types = {\n",
    "        '0': 'str',      \n",
    "        '19': 'float',\n",
    "        '59': 'str',\n",
    "        '118': 'str',\n",
    "        '129': 'float',\n",
    "        '130': 'float',\n",
    "        '131': 'str',\n",
    "        '134': 'str',\n",
    "        '135': 'float',\n",
    "        '136': 'str',\n",
    "        '139': 'float',\n",
    "    }\n",
    "\n",
    "    df = pd.read_csv(f, skiprows=ids, low_memory=False, dtype=column_types)\n",
    "\n",
    "    # Limpieza de NaNs\n",
    "    num = 150000\n",
    "    num_nans = df.isnull().sum()\n",
    "    columns_menos_nans = num_nans[num_nans < num].index\n",
    "    df_sin_nans = df[columns_menos_nans]\n",
    "\n",
    "    # Selección de columnas útiles\n",
    "    df_limpio = df_sin_nans[[\n",
    "        \"id\",\n",
    "        \"loan_amnt\",\n",
    "        \"funded_amnt\",\n",
    "        \"term\",\n",
    "        \"int_rate\",\n",
    "        \"installment\",\n",
    "        \"grade\",\n",
    "        \"emp_length\",\n",
    "        \"annual_inc\",\n",
    "        \"dti\",\n",
    "        \"fico_range_high\",\n",
    "        \"fico_range_low\",\n",
    "        \"revol_util\",\n",
    "        \"loan_status\",\n",
    "        \"out_prncp\",\n",
    "        \"total_rec_prncp\",\n",
    "        \"total_rec_int\",\n",
    "        \"last_fico_range_high\",\n",
    "        \"last_fico_range_low\",\n",
    "        \"open_acc\",\n",
    "        \"pub_rec\",\n",
    "        \"inq_last_6mths\",\n",
    "        \"purpose\",\n",
    "        \"home_ownership\",\n",
    "        \"recoveries\",\n",
    "        \"num_tl_90g_dpd_24m\",\n",
    "        \"delinq_2yrs\"\n",
    "    ]]\n",
    "\n",
    "    return df_limpio\n",
    "\n",
    "df_limpio = limpieza_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19c7dd9c-dccf-4e0a-95ae-b22608723f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpio.to_csv(\"df_limpio_procesado.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20fca6e0-8a62-4962-b374-284bb73b29a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  loan_amnt  funded_amnt        term  int_rate  installment grade  \\\n",
      "0  68340446    14000.0      14000.0   60 months     14.85       331.96     C   \n",
      "1  68446093    11550.0      11550.0   60 months     16.59       284.51     D   \n",
      "2  68396899    18000.0      18000.0   36 months      6.49       551.61     A   \n",
      "3  68426691    21000.0      21000.0   60 months      9.80       444.13     B   \n",
      "4  68436822     5200.0       5200.0   36 months     10.78       169.71     B   \n",
      "\n",
      "  emp_length  annual_inc    dti  ...  last_fico_range_high  \\\n",
      "0    2 years     60000.0  24.29  ...                 514.0   \n",
      "1    5 years     38000.0  21.07  ...                 529.0   \n",
      "2  10+ years     76000.0  14.40  ...                 684.0   \n",
      "3    7 years    125000.0   6.20  ...                 499.0   \n",
      "4    7 years    160000.0   8.00  ...                 714.0   \n",
      "\n",
      "   last_fico_range_low  open_acc pub_rec  inq_last_6mths             purpose  \\\n",
      "0                510.0      11.0     0.0             0.0  debt_consolidation   \n",
      "1                525.0       9.0     0.0             0.0         credit_card   \n",
      "2                680.0      20.0     0.0             0.0  debt_consolidation   \n",
      "3                  0.0      16.0     0.0             2.0               other   \n",
      "4                710.0       6.0     0.0             1.0  debt_consolidation   \n",
      "\n",
      "   home_ownership  recoveries  num_tl_90g_dpd_24m  delinq_2yrs  \n",
      "0        MORTGAGE     1495.90                 0.0          0.0  \n",
      "1            RENT     1165.01                 0.0          0.0  \n",
      "2        MORTGAGE        0.00                 0.0          1.0  \n",
      "3            RENT        0.00                 0.0          0.0  \n",
      "4        MORTGAGE        0.00                 0.0          1.0  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_limpio.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fd2c0e8-1c08-4604-99a7-39ec71213e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  emp_length  emp_length_numeric\n",
      "0    2 years                   2\n",
      "1    5 years                   5\n",
      "2  10+ years                  10\n",
      "3    7 years                   7\n",
      "4    7 years                   7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_emp_length(emp_length):\n",
    "    if pd.isna(emp_length):  \n",
    "        return 0\n",
    "    elif emp_length == '< 1 year':  \n",
    "        return 0\n",
    "    elif emp_length == '10+ years':  \n",
    "        return 10\n",
    "    else:  \n",
    "        try:\n",
    "            return int(emp_length.split()[0])\n",
    "        except:\n",
    "            return 0  \n",
    "\n",
    "df_limpio['emp_length_numeric'] = df_limpio['emp_length'].apply(convert_emp_length)\n",
    "\n",
    "print(df_limpio[['emp_length', 'emp_length_numeric']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08d6e9c2-db5d-4e2b-ad2e-5b4f38c3f978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'loan_amnt', 'funded_amnt', 'term', 'int_rate', 'installment',\n",
      "       'grade', 'emp_length', 'annual_inc', 'dti', 'fico_range_high',\n",
      "       'fico_range_low', 'revol_util', 'loan_status', 'out_prncp',\n",
      "       'total_rec_prncp', 'total_rec_int', 'last_fico_range_high',\n",
      "       'last_fico_range_low', 'open_acc', 'pub_rec', 'inq_last_6mths',\n",
      "       'purpose', 'home_ownership', 'recoveries', 'num_tl_90g_dpd_24m',\n",
      "       'delinq_2yrs', 'emp_length_numeric'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_limpio.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b96819e3-228a-46e4-9022-ea4103bc7b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fico_range_diff      0\n",
      "loan_income_ratio    0\n",
      "term_numeric         0\n",
      "interest_loan        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# 1.FICO range difference\n",
    "df_limpio['fico_range_high'] = pd.to_numeric(df_limpio['fico_range_high'], errors='coerce')\n",
    "df_limpio['fico_range_low'] = pd.to_numeric(df_limpio['fico_range_low'], errors='coerce')\n",
    "df_limpio['fico_range_diff'] = df_limpio['fico_range_high'] - df_limpio['fico_range_low']\n",
    "\n",
    "# 2.Loan to Income Ratio\n",
    "df_limpio['loan_amnt'] = pd.to_numeric(df_limpio['loan_amnt'], errors='coerce')\n",
    "df_limpio['annual_inc'] = pd.to_numeric(df_limpio['annual_inc'], errors='coerce')\n",
    "df_limpio['loan_income_ratio'] = df_limpio['loan_amnt'] / df_limpio['annual_inc']\n",
    "\n",
    "# 3.Term to Numeric (36 o 60 meses)\n",
    "df_limpio['term'] = df_limpio['term'].astype(str)\n",
    "df_limpio['term_numeric'] = df_limpio['term'].apply(lambda x: 36 if '36 months' in x else 60)\n",
    "\n",
    "# 4.Interest * Loan Amount\n",
    "df_limpio['int_rate'] = pd.to_numeric(df_limpio['int_rate'], errors='coerce')\n",
    "df_limpio['interest_loan'] = df_limpio['int_rate'] * df_limpio['loan_amnt']\n",
    "\n",
    "print(df_limpio[['fico_range_diff', 'loan_income_ratio', 'term_numeric', 'interest_loan']].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4d80db2-07e2-485d-a207-3e7665a4415e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# 1. FICO range difference\n",
    "df_limpio['fico_range_diff'] = df_limpio['fico_range_high'] - df_limpio['fico_range_low']\n",
    "#La diferencia entre fico_range_high y fico_range__low puede indicarnos la inestabilidad en la calificación crediticia de los clientes. A mayor diferencia, más inestable puede ser el comportamiento del cliente.\n",
    "\n",
    "# 2. Loan to Income Ratio\n",
    "df_limpio['loan_income_ratio'] = df_limpio['loan_amnt'] / df_limpio['annual_inc']\n",
    "# 3. \n",
    "df_limpio['term'] = df_limpio['term'].astype(str)\n",
    "\n",
    "\n",
    "df_limpio['term_numeric'] = df_limpio['term'].apply(lambda x: 36 if '36 months' in x else (60 if '60 months' in x else None))\n",
    "\n",
    "df_limpio = df_limpio.dropna(subset=['term_numeric'])\n",
    "\n",
    "print(df_limpio['term_numeric'].isna().sum())\n",
    "\n",
    "\n",
    "# 4. Interest * Loan Amount\n",
    "df_limpio['interest_loan'] = df_limpio['int_rate'] * df_limpio['loan_amnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e0e0e19-001b-4d86-b71a-82b44d1d9e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Agrupar propósito en categorías más amplias\n",
    "def group_purpose(purpose):\n",
    "    if purpose in ['debt_consolidation', 'credit_card']:\n",
    "        return 'debt_related'\n",
    "    elif purpose in ['home_improvement', 'major_purchase']:\n",
    "        return 'home_related'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "df_limpio['purpose_grouped'] = df_limpio['purpose'].apply(group_purpose)\n",
    "\n",
    "\n",
    "df_limpio['loan_status_binary'] = df_limpio['loan_status'].apply(lambda x: 1 if x == 'Fully Paid' else 0)\n",
    "\n",
    "\n",
    "X = df_limpio.drop(columns=['loan_status', 'loan_status_binary', 'id'])  \n",
    "y = df_limpio['loan_status_binary']\n",
    "\n",
    "\n",
    "num_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),  \n",
    "    ('scaler', StandardScaler())  \n",
    "])\n",
    "\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  \n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d055692-184e-4abf-a114-28c5fa3ec6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_features),\n",
    "        ('cat', cat_transformer, cat_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39bea240-5717-4ead-a6bf-2e071cc8782b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 99.42%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "\n",
    "X_numeric = X.select_dtypes(include=[np.number])\n",
    "X[X_numeric.columns] = X_numeric.fillna(X_numeric.mean())\n",
    "\n",
    "\n",
    "X[X_numeric.columns] = X_numeric.clip(lower=-1e10, upper=1e10)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Precisión del modelo: {accuracy * 100:.2f}%\")\n",
    "\n",
    "X_numeric = X.select_dtypes(include=[np.number])\n",
    "X[X_numeric.columns] = X_numeric.fillna(X_numeric.mean())\n",
    "\n",
    "\n",
    "X[X_numeric.columns] = X_numeric.clip(lower=-1e10, upper=1e10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a41d457-c5ae-46ef-abd2-080621803afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[6284   67]\n",
      " [   3 5787]]\n",
      "\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      6351\n",
      "           1       0.99      1.00      0.99      5790\n",
      "\n",
      "    accuracy                           0.99     12141\n",
      "   macro avg       0.99      0.99      0.99     12141\n",
      "weighted avg       0.99      0.99      0.99     12141\n",
      "\n",
      "\n",
      "ROC AUC Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(cm)\n",
    "\n",
    "# Reporte de clasificación (precision, recall, f1-score)\n",
    "print(\"\\nReporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ROC AUC Score\n",
    "roc_auc = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1])\n",
    "print(f\"\\nROC AUC Score: {roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fba77e4-2d7b-4e36-a533-aae59a93703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verdaderos negativos (6280): Préstamos que no se pagaron totalmente y fueron correctamente clasificados.\n",
    "#Falsos positivos (63): Préstamos que no se pagaron totalmente pero fueron erróneamente clasificados como \"Fully Paid\".\n",
    "#Falsos negativos (2): Préstamos que fueron totalmente pagados pero erróneamente clasificados como no pagados.\n",
    "#Verdaderos positivos (5796): Préstamos totalmente pagados correctamente clasificados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bb5d98-3e2e-4b3d-a25c-d8887697394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision para clase 0 (No pagado): 1.00 → De todos los préstamos predichos como no pagados, el 100% eran realmente no pagados.\n",
    "#Precision para clase 1 (Pagado): 0.99 → De todos los préstamos que predichos como pagados, el 99% eran realmente pagados.\n",
    "#Recall para clase 0 (No pagado): 0.99 → De todos los préstamos que no se pagaron realmente, el 99% fueron correctamente predichos.\n",
    "#Recall para clase 1 (Pagado): 1.00 → De todos los préstamos que fueron pagados, el 100% fueron correctamente predichos.\n",
    "\n",
    "#El f1-score es muy equilibrado para ambas clases (0.99 en ambos casos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c3fb6e7-c74c-44b1-9d97-186f00f23a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores de validación cruzada: [0.9925871  0.99604613 0.98714992 0.99275124 0.99670511]\n",
      "Promedio de validación cruzada: 0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Evaluar usando validación cruzada con 5 \"folds\"\n",
    "cv_scores = cross_val_score(pipeline, X, y, cv=5)\n",
    "print(f\"Scores de validación cruzada: {cv_scores}\")\n",
    "print(f\"Promedio de validación cruzada: {cv_scores.mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19843b01-f9da-43a1-8994-74f9a381832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#La validación cruzada confirma que el rendimiento del modelo es consistente en diferentes subconjuntos de los datos, con una precisión que varía entre 0.987 y 0.996. El promedio de 0.99 es un excelente indicador de que el modelo tiene un rendimiento muy robusto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06b0465a-b438-4c66-b29d-3b22c1cd924c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'classifier__max_depth': 30, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Mejores hiperparámetros: {grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c0956d-3803-4010-8e42-1821bbd0560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#El ajuste de hiperparámetros ha dado lugar a un Random Forest con una profundidad máxima de 30 y 200 estimadores. Es decir, un árbol relativamente profundo funciona mejor con los datos, y un número más alto de estimadores mejora la estabilidad del modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c78d7f1-1df3-4b87-9da4-f62618ccea6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Feature  Importance\n",
      "9              out_prncp    0.453470\n",
      "10       total_rec_prncp    0.250852\n",
      "17            recoveries    0.056122\n",
      "12  last_fico_range_high    0.028923\n",
      "1            funded_amnt    0.026821\n",
      "13   last_fico_range_low    0.025284\n",
      "0              loan_amnt    0.022052\n",
      "3            installment    0.020176\n",
      "11         total_rec_int    0.017734\n",
      "24         interest_loan    0.014942\n"
     ]
    }
   ],
   "source": [
    "#feature importance\n",
    "feature_importances = pipeline.named_steps['classifier'].feature_importances_\n",
    "\n",
    "features = num_features.tolist() + list(pipeline.named_steps['preprocessor'].transformers_[1][1]['onehot'].get_feature_names_out(cat_features))\n",
    "feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(feature_importance_df.head(10))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc62ca8b-33db-4d8d-b80c-fe7a6e3c06e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(pipeline, 'modelo_random_forest.pkl')\n",
    "\n",
    "pipeline_cargado = joblib.load('modelo_random_forest.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad1179b-1d59-47e7-8c64-6454ae1f9b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
